{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................] 684858 / 684858"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'customer_churn.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下载文件\n",
    "import wget\n",
    "import os\n",
    "#os.chdir(r\"E:\\jupyter_project\\用 Python 和 Tensorflow 2.0 神经网络分类表格数据\")\n",
    "url = 'https://raw.githubusercontent.com/wshuyi/demo-customer-churn-ann/master/customer_churn.csv'\n",
    "filename = wget.detect_filename(url)\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv文件数据\n",
    "import pandas as pd\n",
    "df = pd.read_csv('customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看前几行数据\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看有哪些列\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 对列进行甄别\n",
    "RowNumber：行号，这个对于模型没用，忽略\n",
    "CustomerID：用户编号，这个是顺序发放的，忽略\n",
    "Surname：用户姓名，对流失没有影响，忽略\n",
    "CreditScore：信用分数，这个很重要，保留\n",
    "Geography：用户所在国家/地区，这个有影响，保留\n",
    "Gender：用户性别，可能有影响，保留\n",
    "Age：年龄，影响很大，年轻人更容易切换银行，保留\n",
    "Tenure：当了本银行多少年用户，很重要，保留\n",
    "Balance：存贷款情况，很重要，保留\n",
    "NumOfProducts：使用产品数量，很重要，保留\n",
    "HasCrCard：是否有本行信用卡，很重要，保留\n",
    "IsActiveMember：是否活跃用户，很重要，保留\n",
    "EstimatedSalary：估计收入，很重要，保留\n",
    "Exited：是否已流失，这将作为我们的标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "import warnings  \n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "print('ready') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import feature_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设定一些随机种子值。这主要是为了保证结果可复现。\\\n",
    "首先是 Tensorflow 中的随机种子取值，设定为 1 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照 80:20 的比例，把总体数据(df)分成训练集和测试集。\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把现有训练集(train)的数据，按照 80:20 的比例，分成最终的训练集，以及验证集。\n",
    "train, valid = train_test_split(train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征工程（feature engineering）。\n",
    "因为我们使用的是表格数据（tabular data），属于结构化数据。因此特征工程相对简单一些。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先初始化一个空的特征列表。\n",
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#然后，我们指定，哪些列是数值型数据（numeric data）。\n",
    "numeric_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于这些列，只需要直接指定类型，加入咱们的特征列表就好。\n",
    "for header in numeric_columns:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面是比较讲究技巧的部分了，就是类别数据。\n",
    "类别数据的特点，在于不能直接用数字描述。例如 Geography 包含了国家/地区名称。如果你把法国指定为1， 德国指定为2，电脑可能自作聪明，认为“德国”是“法国”的2倍.\\\n",
    "先看看都有哪些列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以这里编了一个函数，把一个类别列名输入进去，让 Tensorflow 帮我们将其转换成它可以识别的类别形式。\\\n",
    "例如把法国按照 [0, 0, 1]，德国按照 [0, 1, 0] 来表示。这样就不会有数值意义上的歧义了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_from_categorical(colname):\n",
    "  categorical = feature_column.categorical_column_with_vocabulary_list(colname, train[colname].unique().tolist())\n",
    "  return feature_column.indicator_column(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Geography', vocabulary_list=('France', 'Spain', 'Germany'), dtype=tf.string, default_value=-1, num_oov_buckets=0))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尝试输入 Geography 一项，测试一下函数工作是否正常。\n",
    "geography = get_one_hot_from_categorical('Geography'); geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面我们放心大胆地把所有类别数据列都在函数里面跑一遍，并且把结果加入到特征列表中。\n",
    "for col in categorical_columns:\n",
    "  feature_columns.append(get_one_hot_from_categorical(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='CreditScore', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Tenure', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Balance', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='NumOfProducts', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='EstimatedSalary', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Geography', vocabulary_list=('France', 'Spain', 'Germany'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='HasCrCard', vocabulary_list=(1, 0), dtype=tf.int32, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='IsActiveMember', vocabulary_list=(0, 1), dtype=tf.int32, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#看看此时的特征列表内容：6个数值类型，4个类别类型，都没问题了。\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  下面该构造模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接采用 Tensorflow 2.0鼓励开发者使用的 Keras 高级 API 来拼搭一个简单的深度神经网络模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.feature_column.feature_column_v2.DenseFeatures at 0x5066988>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "#把刚刚整理好的特征列表，利用 DenseFeatures 层来表示。\n",
    "#把这样的一个初始层，作为模型的整体输入层。\n",
    "feature_layer = layers.DenseFeatures(feature_columns); feature_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们顺序叠放两个中间层，分别包含200个，以及100个神经元。这两层的激活函数，我们都采用 relu 。\n",
    "relu 函数大概长这个样子：\n",
    "![title](v2_hd.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(200, activation='relu'),\n",
    "  layers.Dense(100, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望输出结果是0或者1，所以这一层只需要1个神经元，而且采用的是 sigmoid 作为激活函数。\\\n",
    "\n",
    "sigmoid 函数的长相是这样的：\n",
    "![title](v3_hd.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型搭建好了，下面我们指定3个重要参数，编译模型。\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，我们选择优化器为 adam 。\n",
    "![title](v4_b.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为评判二元分类效果，所以损失函数选的是 binary_crossentropy。\n",
    "\n",
    "至于效果指标，我们使用的是准确率（accuracy）。\n",
    "\n",
    "模型编译好之后。万事俱备，只差数据了。\n",
    "\n",
    "你可能纳闷，一上来不就已经把训练、验证和测试集分好了吗？\n",
    "\n",
    "没错，但那只是原始数据。我们模型需要接收的，是数据流。\n",
    "\n",
    "在训练和验证过程中，数据都不是一次性灌入模型的。而是一批次一批次分别载入。每一个批次，称作一个 batch；相应地，批次大小，叫做 batch_size 。\n",
    "\n",
    "为了方便咱们把 Pandas 数据框中的原始数据转换成数据流。我这里编写了一个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tfdata(df, shuffle=True, bs=32):\n",
    "  df = df.copy()\n",
    "  labels = df.pop('Exited')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(df), seed=1)\n",
    "  ds = ds.batch(bs)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先是把数据中的标记拆分出来。然后根据把数据读入到 ds 中。根据是否是训练集，我们指定要不要需要打乱数据顺序。然后，依据 batch_size 的大小，设定批次。这样，数据框就变成了神经网络模型喜闻乐见的数据流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df_to_tfdata(train)\n",
    "valid_ds = df_to_tfdata(valid, shuffle=False)\n",
    "test_ds = df_to_tfdata(test, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，只有训练集打乱顺序。因为我们希望验证和测试集一直保持一致。只有这样，不同参数下，对比的结果才有显著意义。\n",
    "\n",
    "有了模型架构，也有了数据，我们把训练集和验证集扔进去，让模型尝试拟合。这里指定了，跑5个完整轮次（epochs）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From d:\\program files\\python\\python37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2758: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From d:\\program files\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1347: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From d:\\program files\\python\\python37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4307: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From d:\\program files\\python\\python37\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4362: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 5.7275 - accuracy: 0.4167 - val_loss: 3.1814 - val_accuracy: 0.7937\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 3.1139 - accuracy: 0.7988 - val_loss: 3.1814 - val_accuracy: 0.7937\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 3.1139 - accuracy: 0.7988 - val_loss: 3.1814 - val_accuracy: 0.7937\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 3.1139 - accuracy: 0.7988 - val_loss: 3.1814 - val_accuracy: 0.7937\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 3.1139 - accuracy: 0.7988 - val_loss: 3.1814 - val_accuracy: 0.7937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5071a88>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          validation_data=valid_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会看到，最终的验证集准确率接近80%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  3200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  20100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  101       \n",
      "=================================================================\n",
      "Total params: 23,401\n",
      "Trainable params: 23,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#我们打印一下模型结构：\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 13ms/step - loss: 3.1829 - accuracy: 0.7925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1829258591409713, 0.7925]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#下面，我们把测试集放入模型中，看看模型效果如何。\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
