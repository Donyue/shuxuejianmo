{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "from jieba.analyse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.txt', 'rb') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.346 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优步 0.28087559478179147\n",
      "司机 0.11995194759665198\n",
      "乘客 0.10548612948502202\n",
      "师傅 0.09588881078154185\n",
      "张师傅 0.08381623349632894\n",
      "目的地 0.07536185128863436\n",
      "网约车 0.07021889869544787\n",
      "姐姐 0.06834121277656388\n",
      "自己 0.06725331106610866\n",
      "上车 0.06232769163083701\n"
     ]
    }
   ],
   "source": [
    "# 使用TF-idf方式提取关键词和权重，并且依次显示出来。指定显示数量为10个关键词。\n",
    "for keyword, weight in extract_tags(data,topK=10, withWeight=True):\n",
    "    print('%s %s' % (keyword, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优步 1.0\n",
      "司机 0.7494059966484155\n",
      "乘客 0.5942845064572533\n",
      "姐姐 0.48545874199064\n",
      "天津 0.4511134903660482\n",
      "目的地 0.4294100274662929\n",
      "时候 0.41808386330346065\n",
      "作者 0.41690383815327287\n",
      "没有 0.3577645150520248\n",
      "活儿 0.2913715664937725\n",
      "上车 0.2770100138843037\n",
      "绕路 0.27460859208431115\n",
      "转载 0.2719329031862934\n",
      "出来 0.24258074539320906\n",
      "出租 0.2386398899911447\n",
      "事儿 0.22870032271337745\n",
      "单数 0.21345068036612438\n",
      "出租车 0.2120496654807952\n",
      "拉门 0.205816713636715\n",
      "跟着 0.205134709860173\n"
     ]
    }
   ],
   "source": [
    "# 另一种关键词提取方式——TextRank。\n",
    "for keyword, weight in textrank(data, withWeight=True):\n",
    "    print('%s %s' % (keyword, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### TF-idf。\n",
    "\n",
    "它的全称是 Term Frequency - inverse document frequency。中间有个连字符，左右两侧各是一部分，共同结合起来，决定某个词的重要程度。\n",
    "\n",
    "第一部分，就是词频（Term Frequency），即某个词语出现的频率。\n",
    "\n",
    "第二部分（idf）,逆文档频率（inverse document frequency）首先计算某个词在各文档中出现的频率。\n",
    "假设一共有10篇文档，其中某个词A在其中10篇文章中都出先过，另一个词B只在其中3篇文中出现。请问哪一个词更关键？\n",
    "答案是B更关键。\n",
    "A可能就是虚词，或者全部文档共享的主题词。而B只在3篇文档中出现，因此很有可能是个关键词。\n",
    "逆文档频率就是把这种文档频率取倒数。这样第一部分和第二部分都是越高越好。二者都高，就很有可能是关键词了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextRank\n",
    "首先会提取词汇，形成节点；然后依据词汇的关联，建立链接。\n",
    "\n",
    "依照连接节点的多少，给每个节点赋予一个初始的权重数值。\n",
    "\n",
    "然后就开始迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
